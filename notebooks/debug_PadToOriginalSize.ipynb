{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test post-processing transform to pad network output to original image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "import logging\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator, _prepare_batch\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset, list_data_collate\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AddChanneld,\n",
    "    NormalizeIntensityd,\n",
    "    AsDiscreted,\n",
    "    Resized,\n",
    "    Compose,\n",
    "    KeepLargestConnectedComponentd,\n",
    "    LoadNiftid,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotated,\n",
    "    RandFlipd,\n",
    "    ToTensord,\n",
    "    MapTransform,\n",
    "    CropForegroundd,\n",
    "    SpatialCrop\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "# from ipynb.fs.full.io_utils import create_data_list\n",
    "sys.path.append(\"/mnt/data/mranzini/Desktop/GIFT-Surg/FBS_Monai/basic_unet_monai/src/\")\n",
    "from io_utils import create_data_list\n",
    "from custom_transform import ConverToOneHotd, MinimumPadd, CropForegroundAnisotropicMargind, PadToOriginalSized\n",
    "\n",
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "cuda_device=2\n",
    "torch.cuda.set_device(cuda_device)\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset\"\n",
    "val_files = [{'img': os.path.join(*[root_dir, \"GroupA\", \"a01_02_Label.nii.gz\"]),\n",
    "              'seg': os.path.join(*[root_dir, \"GroupA\", \"a01_02_Label.nii.gz\"]),\n",
    "              'mask': os.path.join(*[root_dir, \"GroupA\", \"a01_02_Label.nii.gz\"])}]\n",
    "                                \n",
    "\n",
    "# data preprocessing for inference:\n",
    "# - convert data to right format [batch, channel, dim, dim, dim]\n",
    "# - apply whitening\n",
    "# - NOTE: resizing needs to be applied afterwards, otherwise it cannot be remapped back to original size\n",
    "val_transforms = Compose([\n",
    "    LoadNiftid(keys=['img', 'seg', 'mask']),\n",
    "    AddChanneld(keys=['img', 'seg', 'mask']),\n",
    "#     NormalizeIntensityd(keys=['img']),\n",
    "    CropForegroundAnisotropicMargind(keys=['img'], source_key='mask', margin=[20, 20, 5]),\n",
    "    ToTensord(keys=['img', 'seg', 'mask'])\n",
    "])\n",
    "\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = monai.data.DataLoader(val_ds,\n",
    "                                   batch_size=1,\n",
    "                                   num_workers=1)\n",
    "\n",
    "def prepare_batch(batchdata):\n",
    "    assert isinstance(batchdata, dict), \"prepare_batch expects dictionary input data.\"\n",
    "    return (\n",
    "        (batchdata['img'], batchdata['mask'])\n",
    "        if 'mask' in batchdata\n",
    "        else (batchdata['mask'], None)\n",
    "    )\n",
    "\n",
    "valid_data = monai.utils.misc.first(val_loader)\n",
    "print(\"Validation data tensor shapes\")\n",
    "print(valid_data['img'].shape, valid_data['seg'].shape, valid_data['mask'].shape)\n",
    "\n",
    "val_post_transform = PadToOriginalSized(keys=['img'], source_key='mask', margin=[20, 20, 5])\n",
    "output_valid_data = val_post_transform(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = valid_data['seg'].detach().cpu().numpy()\n",
    "crop = valid_data['img'].detach().cpu().numpy()\n",
    "post = output_valid_data['img'].detach().cpu().numpy()\n",
    "\n",
    "print(orig.shape, crop.shape, post.shape)\n",
    "\n",
    "print(np.sum(np.abs(orig-post)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_orig = 18\n",
    "slice_post = 18\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(orig[0, 0, :, :, slice_orig], interpolation=\"nearest\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(post[0, 0, :, :, slice_post], interpolation=\"nearest\")\n",
    "plt.subplot(133)\n",
    "# plt.imshow(crop[0, 0, :, :, 11])\n",
    "plt.imshow(orig[0, 0, :, :, slice_orig] - post[0, 0, :, :, slice_post], interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai0.2.0-venv",
   "language": "python",
   "name": "monai0.2.0-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
