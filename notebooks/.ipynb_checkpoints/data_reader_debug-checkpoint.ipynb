{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Segmentation with UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.1.0\n",
      "Python version: 3.7.4 (default, Jul  9 2019, 03:52:42)  [GCC 5.4.0 20160609]\n",
      "Numpy version: 1.18.2\n",
      "Pytorch version: 1.4.0\n",
      "Ignite version: 0.3.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "import logging\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator, _prepare_batch\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset, list_data_collate\n",
    "from monai.transforms import Compose, LoadNiftid, AddChanneld, AsChannelFirstd, NormalizeIntensityd, Resized, \\\n",
    "     RandSpatialCropd, RandRotated, RandFlipd, Orientationd, ToTensord\n",
    "from monai.transforms.compose import Transform, MapTransform\n",
    "from monai.handlers import \\\n",
    "    StatsHandler, TensorBoardStatsHandler, TensorBoardImageHandler, MeanDice, stopping_fn_from_metric\n",
    "from monai.networks.utils import predict_segmentation\n",
    "\n",
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "cuda_device=1\n",
    "torch.cuda.set_device(cuda_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and validation data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "{'img': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA/a01_02_Image.nii.gz', 'seg': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA/a01_02_Label.nii.gz'}\n",
      "{'img': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE/E18_02_Image.nii.gz', 'seg': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE/E18_02_Label.nii.gz'}\n",
      "50\n",
      "{'img': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA/a04_02_Image.nii.gz', 'seg': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA/a04_02_Label.nii.gz'}\n",
      "{'img': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE/E11_08_Image.nii.gz', 'seg': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE/E11_08_Label.nii.gz'}\n"
     ]
    }
   ],
   "source": [
    "def search_file_in_folder_list(folder_list, file_name):\n",
    "    \"\"\" \n",
    "    search a file with a part of name in a list of folders\n",
    "    :param folder_list: a list of folders\n",
    "    :param file_name: a substring of a file\n",
    "    :param output: the full file name\n",
    "    \"\"\"\n",
    "    file_exist = False\n",
    "    for folder in folder_list:\n",
    "        full_file_name = os.path.join(folder, file_name)\n",
    "        if(os.path.isfile(full_file_name)):\n",
    "            file_exist = True\n",
    "            break\n",
    "    if(file_exist == False):\n",
    "        raise ValueError('file not exist: {0:}'.format(file_name))\n",
    "    return full_file_name\n",
    "\n",
    "def create_data_list(data_folder_list, subject_list, img_postfix='_Image', label_postfix='_Label'):\n",
    "    \"\"\" \n",
    "    create list of all file paths \n",
    "    :param data_folder_list: list of directories to search\n",
    "    :param subject_list: list of subject prefix to search (expected filename: <subject_prefix><postfix>.nii.gz)\n",
    "    :param img_postfix: postfix for image filenames \n",
    "    :param label_postfix: postfix for label filenames\n",
    "    :return list of paths to existing files with matched name\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(data_folder_list, str):\n",
    "        data_folder_list = [data_folder_list]\n",
    "    if isinstance(subject_list, str):\n",
    "        subject_list = [subject_list]\n",
    "    \n",
    "    full_list = []\n",
    "    for scan_list in subject_list:\n",
    "        with open(scan_list) as f:\n",
    "            for line in f:\n",
    "                subject = line.rstrip()\n",
    "                image_basename = \"{}{}.nii.gz\".format(subject, img_postfix)\n",
    "                image_filename = search_file_in_folder_list(data_folder_list, image_basename)\n",
    "                label_basename = \"{}{}.nii.gz\".format(subject, label_postfix)\n",
    "                label_filename = search_file_in_folder_list(data_folder_list, label_basename)\n",
    "                if os.path.isfile(image_filename) and os.path.isfile(label_filename):\n",
    "                    full_list.append({'img': image_filename, 'seg': label_filename})\n",
    "    return full_list\n",
    "    \n",
    "# list folders to search for the data\n",
    "data_root = [\"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA\", \n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupB1\",\n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupB2\", \n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupC\",\n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupD\",\n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE\",\n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupF\"]\n",
    "\n",
    "# list of subject IDs to search for data\n",
    "list_root = \"/mnt/data/mranzini/Desktop/GIFT-Surg/Retraining_with_expanded_dataset/config/file_names\"\n",
    "training_list = os.path.join(list_root, \"list_train_files.txt\")\n",
    "validation_list = [os.path.join(list_root, \"list_validation_h_files.txt\"),\n",
    "                   os.path.join(list_root, \"list_validation_p_files.txt\")]\n",
    "\n",
    "# \n",
    "train_files = create_data_list(data_folder_list=data_root, \n",
    "                               subject_list=training_list, \n",
    "                               img_postfix='_Image', \n",
    "                               label_postfix='_Label')\n",
    "\n",
    "print(len(train_files))\n",
    "print(train_files[0])\n",
    "print(train_files[-1])\n",
    "\n",
    "val_files = create_data_list(data_folder_list=data_root, \n",
    "                             subject_list=validation_list, \n",
    "                             img_postfix='_Image', \n",
    "                             label_postfix='_Label')\n",
    "print(len(val_files))\n",
    "print(val_files[0])\n",
    "print(val_files[-1])\n",
    "\n",
    "# np.savetxt(\"images_training.txt\", images_training, fmt='%s')\n",
    "# np.savetxt(\"seg_training.txt\", seg_training, fmt='%s')\n",
    "# np.savetxt(\"images_validation.txt\", images_validation, fmt='%s')\n",
    "# np.savetxt(\"seg_validation.txt\", seg_validation, fmt='%s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup transforms, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/monai/data/utils.py\", line 195, in list_data_collate\n    return default_collate(data)\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 35 and 45 in dimension 4 at /pytorch/aten/src/TH/generic/THTensor.cpp:612\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8ed51993b2f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m check_loader = DataLoader(check_ds, batch_size=2, num_workers=1, collate_fn=list_data_collate,\n\u001b[1;32m     75\u001b[0m                           pin_memory=torch.cuda.is_available())\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mcheck_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/monai-python3.7/lib/python3.7/site-packages/monai/utils/misc.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(iterable, default)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0miterable\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeaningful\u001b[0m \u001b[0mmostly\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m'for'\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/monai-python3.7/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/monai/data/utils.py\", line 195, in list_data_collate\n    return default_collate(data)\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/mnt/data/mranzini/environments/monai-python3.7/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 35 and 45 in dimension 4 at /pytorch/aten/src/TH/generic/THTensor.cpp:612\n"
     ]
    }
   ],
   "source": [
    "# define transforms for image and segmentation\n",
    "\n",
    "class SqueezeDim(Transform):\n",
    "    \"\"\"\n",
    "    Remove last dimension\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim (int): dimension to be squeezed.\n",
    "                Default: None (all dimensions of size 1 will be removed)\n",
    "        \"\"\"\n",
    "        if dim is not None:\n",
    "            assert isinstance(dim, int) and dim >= -1, 'invalid channel dimension.'\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (dict): dictionary of numpy arrays with dim removed,\n",
    "        \"\"\"\n",
    "        return np.squeeze(img, self.dim)\n",
    "\n",
    "    \n",
    "class SqueezeDimd(MapTransform):\n",
    "    \"\"\"\n",
    "    Dictionary-based wrapper of :py:class:SqueezeDim`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, keys, dim=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            keys (hashable items): keys of the corresponding items to be transformed.\n",
    "                See also: :py:class:`monai.transforms.compose.MapTransform`\n",
    "            dim (int): dimension to be squeezed.\n",
    "                Default: None (all dimensions of size 1 will be removed)\n",
    "        \"\"\"\n",
    "        super().__init__(keys)\n",
    "        self.converter = SqueezeDim(dim=dim)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            d[key] = self.converter(d[key])\n",
    "        return d\n",
    "        \n",
    "    \n",
    "# def squeeze(data):\n",
    "#     data=dict(data)\n",
    "#     data['img']=data['img'][...,0]\n",
    "#     data['seg']=data['seg'][...,0]\n",
    "#     return data\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadNiftid(keys=['img', 'seg']),\n",
    "    AddChanneld(keys=['img', 'seg']),\n",
    "    NormalizeIntensityd(keys=['img']),\n",
    "    Resized(keys=['img'], spatial_size=[96, 96], order=1),\n",
    "    Resized(keys=['seg'], spatial_size=[96, 96], order=0, anti_aliasing=False),\n",
    "    RandSpatialCropd(keys=['img', 'seg'], roi_size=[96, 96, 1], random_size=False),\n",
    "    RandRotated(keys=['img', 'seg'], degrees=90, prob=0.2, spatial_axes=[0, 1], order=0, reshape=False),\n",
    "    RandFlipd(keys=['img', 'seg'], spatial_axis=[0, 1]),\n",
    "    SqueezeDimd(keys=['img', 'seg'], dim=-1),\n",
    "    ToTensord(keys=['img', 'seg'])\n",
    "])\n",
    "\n",
    "check_train_files = train_files[:10]\n",
    "# print(check_train_files)\n",
    "\n",
    "# define dataset, data loader\n",
    "check_ds = monai.data.Dataset(data=check_train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images \n",
    "check_loader = DataLoader(check_ds, batch_size=2, num_workers=1, collate_fn=list_data_collate,\n",
    "                          pin_memory=torch.cuda.is_available())\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(check_data['img'].shape, check_data['seg'].shape)\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(check_data['img'][0, 0, :, :], cmap='gray')\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(check_data['seg'][0, 0, :, :])\n",
    "\n",
    "# val_transforms = Compose([\n",
    "#     LoadNiftid(keys=['img', 'seg']),\n",
    "#     AddChanneld(keys=['img', 'seg']),\n",
    "#     NormalizeIntensityd(keys=['img']),\n",
    "#     Resized(keys=['img'], spatial_size=[96, 96], order=1),\n",
    "#     Resized(keys=['seg'], spatial_size=[96, 96], order=0, anti_aliasing=False),\n",
    "#     ToTensord(keys=['img', 'seg'])\n",
    "# ])\n",
    "\n",
    "# # create a training data loader\n",
    "# train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# train_loader = DataLoader(train_ds, batch_size=10, shuffle=True, num_workers=4,\n",
    "#                           collate_fn=list_data_collate, pin_memory=torch.cuda.is_available())\n",
    "# check_train_data = monai.utils.misc.first(train_loader)\n",
    "# print(check_train_data['img'].shape, check_train_data['seg'].shape)\n",
    "\n",
    "# # create a validation data loader\n",
    "# val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "# val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate,\n",
    "#                         pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data['seg'][0, 0, 50, 40:60, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai-venv",
   "language": "python",
   "name": "monai-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
