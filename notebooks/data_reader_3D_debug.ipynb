{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data reading and preprocessing for fetal brain segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.2.0\n",
      "Python version: 3.7.4 (default, Jul  9 2019, 03:52:42)  [GCC 5.4.0 20160609]\n",
      "Numpy version: 1.18.2\n",
      "Pytorch version: 1.4.0\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.0.2\n",
      "scikit-image version: 0.16.2\n",
      "Pillow version: 7.1.1\n",
      "Tensorboard version: 2.2.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "import logging\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator, _prepare_batch\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset, list_data_collate\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AddChanneld,\n",
    "    NormalizeIntensityd,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    KeepLargestConnectedComponentd,\n",
    "    LoadNiftid,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotated,\n",
    "    RandFlipd,\n",
    "    ToTensord,\n",
    "    MapTransform\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "from ipynb.fs.full.io_utils import create_data_list\n",
    "\n",
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "cuda_device=1\n",
    "torch.cuda.set_device(cuda_device)\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and validation data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "{'img': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA/a01_02_Image.nii.gz', 'seg': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA/a01_02_Label.nii.gz'}\n",
      "{'img': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE/E18_02_Image.nii.gz', 'seg': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE/E18_02_Label.nii.gz'}\n",
      "50\n",
      "{'img': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA/a04_02_Image.nii.gz', 'seg': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA/a04_02_Label.nii.gz'}\n",
      "{'img': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE/E11_08_Image.nii.gz', 'seg': '/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE/E11_08_Label.nii.gz'}\n"
     ]
    }
   ],
   "source": [
    "# list folders to search for the data\n",
    "data_root = [\"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupA\", \n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupB1\",\n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset/GroupB2\", \n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupC\",\n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupD\",\n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupE\",\n",
    "             \"/mnt/data/mranzini/Desktop/GIFT-Surg/Data/NeuroImage_dataset_extension/GroupF\"]\n",
    "\n",
    "# list of subject IDs to search for data\n",
    "list_root = \"/mnt/data/mranzini/Desktop/GIFT-Surg/Retraining_with_expanded_dataset/config/file_names\"\n",
    "training_list = os.path.join(list_root, \"list_train_files.txt\")\n",
    "validation_list = [os.path.join(list_root, \"list_validation_h_files.txt\"),\n",
    "                   os.path.join(list_root, \"list_validation_p_files.txt\")]\n",
    "\n",
    "# \n",
    "train_files = create_data_list(data_folder_list=data_root, \n",
    "                               subject_list=training_list, \n",
    "                               img_postfix='_Image', \n",
    "                               label_postfix='_Label')\n",
    "\n",
    "print(len(train_files))\n",
    "print(train_files[0])\n",
    "print(train_files[-1])\n",
    "\n",
    "val_files = create_data_list(data_folder_list=data_root, \n",
    "                             subject_list=validation_list, \n",
    "                             img_postfix='_Image', \n",
    "                             label_postfix='_Label')\n",
    "print(len(val_files))\n",
    "print(val_files[0])\n",
    "print(val_files[-1])\n",
    "\n",
    "# np.savetxt(\"images_training.txt\", images_training, fmt='%s')\n",
    "# np.savetxt(\"seg_training.txt\", seg_training, fmt='%s')\n",
    "# np.savetxt(\"images_validation.txt\", images_validation, fmt='%s')\n",
    "# np.savetxt(\"seg_validation.txt\", seg_validation, fmt='%s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup transforms, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConverToOneHotd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert multi-class label to One Hot Encoding:\n",
    "    \"\"\"\n",
    "    def __init__(self, keys, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            \n",
    "        \"\"\"\n",
    "        super().__init__(keys)\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = list()\n",
    "            for n in self.labels:\n",
    "                result.append(d[key] == n)\n",
    "            d[key] = np.stack(result, axis=0).astype(np.float32)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "torch.Size([4, 1, 256, 256, 24]) torch.Size([4, 1, 256, 256, 24])\n"
     ]
    }
   ],
   "source": [
    "num_classes = 1\n",
    "seg_labels = [1]\n",
    "patch_size = [256, 256, 24] \n",
    "\n",
    "# data preprocessing for training:\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"img\", \"seg\"]),\n",
    "        ConverToOneHotd(keys=['seg'], labels=seg_labels),\n",
    "        AddChanneld(keys=['img']),\n",
    "        NormalizeIntensityd(keys=['img']),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"img\", \"seg\"], label_key=\"seg\", spatial_size=patch_size, pos=1, neg=1, num_samples=2\n",
    "        ),\n",
    "        RandRotated(keys=['img', 'seg'], range_x=90, range_y=90, prob=0.5, keep_size=True,\n",
    "                    mode=[\"bilinear\", \"nearest\"]),\n",
    "        RandFlipd(keys=['img', 'seg'], spatial_axis=[0, 1]),\n",
    "        ToTensord(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "# create training data loader\n",
    "check_train_files = train_files\n",
    "print(len(check_train_files))\n",
    "\n",
    "# define dataset, data loader\n",
    "check_ds = monai.data.Dataset(data=check_train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images \n",
    "check_loader = monai.data.DataLoader(check_ds,\n",
    "                                     batch_size=2,\n",
    "                                     shuffle=True, num_workers=1,\n",
    "                                     pin_memory=torch.cuda.is_available())\n",
    "\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(check_data['img'].shape, check_data['seg'].shape)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(check_data['img'][0, 0, :, :, 8], cmap='gray')\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(check_data['seg'][0, 0, :, :, 8], interpolation=\"nearest\")\n",
    "# print(\"Segmentation limits: channel 0\")\n",
    "# print(torch.min(check_data['seg'][0, 0, :, :, 8]))\n",
    "# print(torch.max(check_data['seg'][0, 0, :, :, 8]))\n",
    "# if num_classes == 2:\n",
    "#     plt.subplot(133)\n",
    "#     plt.imshow(check_data['seg'][0, 1, : , :, 8], interpolation=\"nearest\")\n",
    "#     print(\"Segmentation limits: channel 1\")\n",
    "#     print(torch.min(check_data['seg'][0, 1, :, :, 8]))\n",
    "#     print(torch.max(check_data['seg'][0, 1, :, :, 8]))\n",
    "########\n",
    "# val_transforms = Compose([\n",
    "#     LoadNiftid(keys=['img', 'seg']),\n",
    "#     AddChanneld(keys=['img', 'seg']),\n",
    "#     NormalizeIntensityd(keys=['img']),\n",
    "#     Resized(keys=['img'], spatial_size=[96, 96], order=1),\n",
    "#     Resized(keys=['seg'], spatial_size=[96, 96], order=0, anti_aliasing=False),\n",
    "#     ToTensord(keys=['img', 'seg'])\n",
    "# ])\n",
    "\n",
    "# # create a training data loader\n",
    "# train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# train_loader = DataLoader(train_ds, batch_size=10, shuffle=True, num_workers=4,\n",
    "#                           collate_fn=list_data_collate, pin_memory=torch.cuda.is_available())\n",
    "# check_train_data = monai.utils.misc.first(train_loader)\n",
    "# print(check_train_data['img'].shape, check_train_data['seg'].shape)\n",
    "\n",
    "# # create a validation data loader\n",
    "# val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "# val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate,\n",
    "#                         pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai0.2.0-venv",
   "language": "python",
   "name": "monai0.2.0-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
